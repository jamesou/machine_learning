{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "title": ""
    },
    "id": "mSudRe0SX-H6"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The \"MLflow PySpark Pipeline for Diabetes Prediction\" - Python Notebook is a comprehensive example of how to use the MLflow library to build a machine learning pipeline to predict diabetes in patients. The notebook demonstrates how to use various PySpark libraries, such as Pipeline, PipelineModel, Logistic Regression, BinaryClassificationEvaluator, and MulticlassClassificationEvaluator to build and evaluate the machine learning model.\n",
    "\n",
    "**This Python Notebook runs only in Azure/GCP/AWS Databricks.**\n",
    "\n",
    "The first step is to set the MLflow experiment for diabetes prediction. The next step is to load the diabetes dataset, which is split into training and test sets using the randomSplit function. The hyperparameters for the logistic regression model are set, and the model is trained using the pipeline function.\n",
    "\n",
    "The categorical features in the dataset are converted to numeric using StringIndexer, and the features vector is created using VectorAssembler. The logistic regression model is defined, and the pipeline is created using these components. The hyperparameters are logged, and the model is trained.\n",
    "\n",
    "After training the model, the predictions are made on the test data, and the model is evaluated using BinaryClassificationEvaluator and MulticlassClassificationEvaluator. The evaluation metrics, such as area under the ROC curve and accuracy, are logged using the mlflow.log_metric function.\n",
    "\n",
    "The model is then logged using the mlflow.spark.log_model function, which saves the model to the MLflow registry. Finally, the production version of the model is transitioned using the MlflowClient function. Then, The model is then loaded and used to make predictions on new data.\n",
    "\n",
    "This notebook is written in **Python** so the default cell type is Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9431f67c-e7ff-4496-becc-3381f024e99b",
     "showTitle": false,
     "title": ""
    },
    "id": "AMWDU8rLX-H_",
    "outputId": "739dfb53-d575-4fa5-fc78-dca5bde08211"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/25 19:30:58 INFO mlflow.tracking.fluent: Experiment with name 'diabetes-prediction' does not exist. Creating a new experiment.\n",
      "23/09/25 19:31:00 WARN Utils: Your hostname, JamesoudeMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.68.71 instead (on interface en0)\n",
      "23/09/25 19:31:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/25 19:31:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/25 19:31:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/09/25 19:31:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Set the MLflow experiment\n",
    "mlflow.set_experiment(\"diabetes-prediction\")\n",
    "\n",
    "\n",
    "# Load the diabetes data\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "data = spark.read.csv(\"./diabetes_prediction_dataset.csv\", inferSchema=True,header=True)\n",
    "\n",
    "# Convert the diabetes label to double\n",
    "data = data.withColumn(\"diabetes\", col(\"diabetes\").cast(DoubleType()))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3], seed=1234)\n",
    "\n",
    "# Set the hyperparameters for the logistic regression model\n",
    "lr_params = {\n",
    "    \"regParam\": 0.01,\n",
    "    \"elasticNetParam\": 0.0,\n",
    "    \"maxIter\": 100\n",
    "}\n",
    "\n",
    "\n",
    "# Train the model and make predictions on the test data\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Convert categorical features to numeric using StringIndexer\n",
    "    GenderIndexer = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\")                       \n",
    "    SmokeHistIndexer = StringIndexer(inputCol=\"smoking_history\", outputCol=\"smoking_statusIndex\")  \n",
    "\n",
    "    # Create the features vector using VectorAssembler\n",
    "    F_assembler = VectorAssembler(inputCols=[\"genderIndex\", \"age\", \"hypertension\", \"heart_disease\", \"smoking_statusIndex\", \"bmi\",\"HbA1c_level\",\"blood_glucose_level\"], outputCol=\"features\")\n",
    "    \n",
    "    # Define the logistic regression model\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=\"diabetes\")\n",
    "  \n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline(stages=[GenderIndexer, SmokeHistIndexer,F_assembler, lr])\n",
    "    \n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(lr_params)\n",
    "    \n",
    "    # Train the model\n",
    "    models=pipeline.fit(trainingData)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    predictions = models.transform(testData)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    auc_evaluator = BinaryClassificationEvaluator(labelCol=\"diabetes\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "    areaUnderROC = auc_evaluator.evaluate(predictions)\n",
    "    print(\"Area under ROC curve: {}\".format(areaUnderROC))\n",
    "    acc_evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"diabetes\", metricName=\"accuracy\")\n",
    "    accuracy = acc_evaluator.evaluate(predictions)\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "    \n",
    "    #Log the metrics\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy*100)\n",
    "    mlflow.log_metric(\"AUC\", areaUnderROC)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.spark.log_model(models,\"model\")\n",
    "\n",
    "    #Get the ID of the current run\n",
    "    runid=mlflow.active_run().info.run_id\n",
    "    model_uri='runs:/'+runid+'/model' #Here we are constructing the model URI using the run ID of the active run and the 'model' endpoint\n",
    "    model_name=\"Diabetes_prediction_model\" #Set the name for the registered model\n",
    "    model_details=mlflow.register_model(model_uri=model_uri,name=model_name) #Register the trained model with the name and URI specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a640848-e3b0-4113-9c09-5b6268be18ab",
     "showTitle": false,
     "title": ""
    },
    "id": "D1rjn5K1X-IA",
    "outputId": "ebfa5b91-7afe-44aa-d540-92873ee0a31f"
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient  #Import the Mlflow client library\n",
    "\n",
    "client=MlflowClient() #Create a client instance for accessing the Mlflow tracking server\n",
    "client.transition_model_version_stage(name=model_details.name,version=model_details.version,stage='Production') #Staging the registered model version to the production stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b81e4b3-6a6c-43de-8f67-27c625927961",
     "showTitle": false,
     "title": ""
    },
    "id": "QO8h0uQCX-IA",
    "outputId": "8ab62b3d-1041-45d8-ba67-f447ddf61c27"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "#Load the saved MLflow model\n",
    "loaded_model = mlflow.spark.load_model(model_uri)\n",
    "\n",
    "#Create a new test dataset as a Spark dataframe\n",
    "test = spark.createDataFrame([\n",
    "    ('Female',39.0,0,1,\"No Info\",79,8.8,145)], [\"gender\", \"age\", \"hypertension\",\"heart_disease\",\"smoking_history\",\"bmi\",\"HbA1c_level\",\"blood_glucose_level\"])\n",
    "\n",
    "#Use the loaded model to make predictions on the new dataset\n",
    "new_predictions=loaded_model.transform(test)\n",
    "#Display the predicted output\n",
    "new_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict_data = {'gender': 'Female', 'age': 39, 'hypertension': 1, 'heart_disease': 0, 'smoking_history': 'No Info', 'bmi': 79, 'HbA1c_level': 8.8, 'blood_glucose_level': 145}\n",
    "df = pd.DataFrame.from_dict(dict_data, orient=\"index\")\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(df)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "diabetes_prediction_notebook",
   "notebookOrigID": 4430474130799444,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
