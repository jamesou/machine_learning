import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression 
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.metrics import precision_recall_fscore_support,roc_auc_score,precision_recall_curve
import mlflow
#load dataset
df = pd.read_csv("./diabetes_prediction_dataset.csv")
df.head()


#check missed column
df.isna().sum()


# check the recoreds numer and column
df.shape


# delete duplicated data
df = df.drop_duplicates()
df.duplicated().sum()
# check the recoreds numer and column
df.shape


df.diabetes.value_counts().plot(kind = 'pie', autopct = '%1.1f%%', shadow = True)
plt.title('Distribution of Diabetes')
plt.show()


# feature analysing
# ploting categorical features alongiside target feature
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 8))

# Distribution of gender
sns.countplot(x="gender", data=df,hue = 'diabetes',ax=axes[0, 0])
axes[0, 0].set_title("Distribution of Diabetes status within Gender")
axes[0, 0].set_xlabel("Gender")
axes[0, 0].set_ylabel("Count")

# Distribution of Hypertension
sns.countplot(x="hypertension", data=df, hue = 'diabetes', ax=axes[0, 1])
axes[0, 1].set_title("Distribution of Diabetes status within Hypertension")
axes[0, 1].set_xlabel("Hypertension")
axes[0, 1].set_ylabel("Count")

# Chart 3: Distribution of heart disease
sns.countplot(x="heart_disease", hue = 'diabetes',data=df, ax=axes[1, 0])
axes[1, 0].set_title("Distribution of Diabetes status within Heart Disease")
axes[1, 0].set_xlabel("Heart Disease")
axes[1, 0].set_ylabel("Count")

# Chart 4: Distribution of smoking history
sns.countplot(x="smoking_history", data=df, hue = 'diabetes', ax=axes[1, 1])
axes[1, 1].set_title("Distribution of Diabetes status within Smoking History")
axes[1, 1].set_xlabel("Smoking History")
axes[1, 1].set_ylabel("Count")

plt.tight_layout()
plt.show()


# Create subplots
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))

# List of numeric feature columns
numeric_features = ['age', 'bmi','HbA1c_level', 'blood_glucose_level']

# Loop through numeric features and plot them
for i, feature in enumerate(numeric_features):
    row = i // 2
    col = i % 2
    sns.histplot(df[feature], ax=axes[row, col])
    axes[row, col].set_title(f'{feature}')

# Adjust layout
plt.tight_layout()

# Show the plots
plt.show()
df.describe()


# enumerate type is encoded from string to 0,1
df_encoded = pd.get_dummies(df, columns=['gender', 'smoking_history'])
df_encoded.columns


df_encoded.head()


columns = ['gender_Female', 'gender_Male',
       'gender_Other', 'smoking_history_No Info', 'smoking_history_current',
       'smoking_history_ever', 'smoking_history_former',
       'smoking_history_never', 'smoking_history_not current']
# cast type to int  
df_encoded[columns] = df_encoded[columns].astype(int)
df_encoded_metamorphic_test = df_encoded.copy() # for metamorphic test
# ensure that all features have the same scale or unit variance for algorithm. 
# in order to use metamorphic test, we remove the scaler
# for numeric features
# scaler = StandardScaler()
# df_encoded[numeric_features] = scaler.fit_transform(df_encoded[numeric_features])
# df_encoded.head(20)


X = df_encoded.drop('diabetes', axis = 1)
y = df_encoded.diabetes
# split the source(X) and target(y) into train and test  20% for test, 80% for training
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)
X_train.shape, y_train.shape, X_test.shape, y_test.shape


y_train.value_counts()


# keep the training data balance to reduce bias and overfitting
smote = SMOTE(sampling_strategy = 'auto', random_state = 42)
X_train_resampled, y_train_resampled =smote.fit_resample(X_train, y_train)
y_train_resampled.value_counts()


run = mlflow.active_run()
if run:
    print("Active run_id: {}".format(run.info.run_id))
    mlflow.end_run()

mlflow.set_experiment('diabetes_prediction') 
mlflow.set_tracking_uri("http://localhost:5000/") # Actual Server URI instead of localhost
experiment = mlflow.get_experiment_by_name("diabetes_prediction")
# set classfiers and select the best performance one from them
params = {
    'criterion': 'entropy',
    'max_depth': 1000,
    'max_features': 'sqrt',
    'min_samples_leaf': 4,
    'min_samples_split': 5,
    'n_estimators': 600,
    ###
    'n_jobs': -1,
    'random_state': 42
}
classifiers = [
        ("Logistic_Regression", LogisticRegression(max_iter=10000)),
        # Log parameters, different model have different parameters
        ("Random_Forest", RandomForestClassifier(**params)),
        #("Random_Forest", RandomForestClassifier()),
        ("SVM", SVC()), #spend on a lot of time
        ("K_Nearest_Neighbors", KNeighborsClassifier())
        ]
# Iterate through classifiers, fit, and evaluate them
for name, classifier in classifiers:
    # if "Random_Forest" == name:
    #     mlflow.log_param("n_estimators", 100)
    #     mlflow.log_param("max_depth", 10)
    # Start MLflow run
    with mlflow.start_run(nested=True,run_name=name) as run:
        classifier.fit(X_train_resampled, y_train_resampled)
        y_pred = classifier.predict(X_test)
        # Calculate accuracy
        accuracy = accuracy_score(y_test, y_pred)
        print(f"Model: {name}")
        print(f"Accuracy: {accuracy:.2f}")
        # Display classification report
        report = classification_report(y_test, y_pred)
        print(f"Classification Report:\n{report}")
        precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)
        # Log metrics 
        # print(f"precision:\n{precision}")
        # print(f"recall:\n{recall}")
        # print(f"fscore:\n{fscore}")
        # print(f"support:\n{support}")
        roc_auc = roc_auc_score(y_test, y_pred)
        print(f"roc_auc:\n{roc_auc}")
        metrics = {"accuracy":accuracy, 
                   "precision":float(precision[0]), 
                   "recall":float(recall[0]), 
                   "fscore":float(fscore[0]), 
                   "support":float(support[0]), 
                   "roc_auc":float(roc_auc)
        }
        mlflow.log_metrics(metrics)
        mlflow.log_param("model", name)
        precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred)
        # print(f"precisions:\n{precisions}")
        # print(f"recalls:\n{recalls}")
        # print(f"thresholds:\n{thresholds}")
        #PR diagram
        plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')
        plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')
        plt.xlabel('Threshold')
        plt.legend(loc='center right')
        plt.ylim([0, 1])
        plt.show()
        # Display confusion matrix
        confusion = confusion_matrix(y_test, y_pred)
        print(f"Confusion Matrix:\n{confusion}")
        mlflow.sklearn.log_model(classifier, name)
        print("Details logged at: %s" % mlflow.get_tracking_uri())
        print("Run ID: %s" % run.info.run_uuid)
        print("=" * 50)
    mlflow.end_run()


# By test the algorithm, we get the best one is Random forest
# the next step we should test the modelling with metamorphic test
model_name = 'Random_Forest'
randomForest = RandomForestClassifier()
# re-training
randomForest.fit(X_train_resampled, y_train_resampled)
y_pred = randomForest.predict(X_test)
# Calculate accuracy
accuracy_radmon_forest = accuracy_score(y_test, y_pred)
print(f"Model: {model_name}")
print(f"Accuracy: {accuracy_radmon_forest}")


# increasing the patient's age by 10 years, or by decreasing the patient's bmi by 5%. 
# we choose increasing age by 10 years as an example
# if we get similar accruracy rate with incresing before, which means pass the metamorphic test
# numer features 'age', 'bmi','HbA1c_level', 'blood_glucose_level'
increased_age = 10
df_encoded_metamorphic_test['age'] = df_encoded_metamorphic_test['age'] + increased_age
df_encoded_metamorphic_test.head()


# prepare the test data
X = df_encoded_metamorphic_test.drop('diabetes', axis = 1)
y = df_encoded_metamorphic_test.diabetes
# split the source(X) and target(y) into train and test  20% for test, 80% for training
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)
X_train.shape, y_train.shape, X_test.shape, y_test.shape
# keep the training data balance to reduce bias and overfitting
smote = SMOTE(sampling_strategy = 'auto', random_state = 42)
X_train_resampled, y_train_resampled =smote.fit_resample(X_train, y_train)
randomForest = RandomForestClassifier(**params)
# re-training
randomForest.fit(X_train_resampled, y_train_resampled)
# joblib.dump(model, "rf.pkl") #no need, use MFflow online model
y_pred = randomForest.predict(X_test)
# Calculate accuracy
accuracy_metamorphic_test = accuracy_score(y_test, y_pred)
# metamorphic_relation
print(f"Model: {model_name}")
print(f"Accuracy: {accuracy_metamorphic_test}")
if str(accuracy_metamorphic_test)[0:4] == str(accuracy_radmon_forest)[0:4]:
    print(f"Metamorphic relation holds: Prediction for accuracy ({accuracy_radmon_forest}). "
          f"After increased age by ({increased_age} years), the accuracy ({accuracy_metamorphic_test}) is similar.")
else:
    print(f"Metamorphic relation does not hold.")


dict_data = {"age": 39, "hypertension": 1, "heart_disease": 0, "bmi": 79, "HbA1c_level": 8.8, "blood_glucose_level": 145, "gender_Female": 1, "gender_Male": 0, "gender_Other": 0, "smoking_history_No Info": 1, "smoking_history_current": 0, "smoking_history_ever": 0, "smoking_history_former": 0, "smoking_history_never": 0, "smoking_history_not current": 0},
print(type(dict_data))
df = pd.DataFrame.from_dict(dict_data)
print(df)
y_pred = randomForest.predict(df)
print(y_pred)
# Add MLFlow api for collecting the model metric data --Done
# MLFlow tables structure and business structure
# deploy a model file and implement a RestAPI inferface for application --Done
# design a webpage and request the RestAPI after submitting the 'prediction' button to get the prediction result



